{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Gradient Boosting Learner in AMH\n",
    "\n",
    "    This model inherits sklearn.ensemble.GradientBoostingClassifier by \n",
    "    incoporating C-stat, Maximum KS & decile lift which are most impor-\n",
    "    tant statistics to validate model prediction for campaign targeting\n",
    "    (order ranking).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.artist\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.ticker import Formatter, FixedLocator\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingLearner_Shawn(GradientBoostingClassifier):\n",
    "    def __init__(self,loss='deviance',learning_rate=0.1,n_estimators=100,subsample=1.0,criterion='friedman_mse',min_samples_split=2,min_samples_leaf=1,min_weight_fraction_leaf=0.,max_depth=3,min_impurity_split=1e-7,init=None,random_state=None,max_features=None,verbose=0,max_leaf_nodes=None,warm_start=False,presort='auto',df_in=None,str_group=None,str_score=None,str_resp=None,fmt_count=None,fmt_group=None,fmt_resp=None,fmt_resp_rate=None,fmt_rand_rate=None):\n",
    "        super(GradientBoostingClassifier, self).__init__(loss=loss,\n",
    "                                                         learning_rate=learning_rate, \n",
    "                                                         n_estimators=n_estimators,\n",
    "                                                         criterion=criterion, \n",
    "                                                         min_samples_split=min_samples_split,\n",
    "                                                         min_samples_leaf=min_samples_leaf,\n",
    "                                                         min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                                                         max_depth=max_depth, \n",
    "                                                         init=init, \n",
    "                                                         subsample=subsample,\n",
    "                                                         max_features=max_features,\n",
    "                                                         random_state=random_state, \n",
    "                                                         verbose=verbose,\n",
    "                                                         max_leaf_nodes=max_leaf_nodes,\n",
    "                                                         min_impurity_split=min_impurity_split,\n",
    "                                                         warm_start=warm_start,\n",
    "                                                         presort=presort)\n",
    "        '''self.df_in=df_in'''\n",
    "        self.str_score = 'score'\n",
    "        self.str_resp=str_resp\n",
    "        self.str_group = 'group'\n",
    "        self.fmt_resp = 'response'\n",
    "        self.fmt_group='group'\n",
    "        self.fmt_resp_rate='response_rate'\n",
    "        self.fmt_rand_rate='random select'\n",
    "        self.fmt_count='cust_cnt'\n",
    "        \n",
    "    def decile_lift(self, df_scored):\n",
    "        '''\n",
    "        df_in: a dataframe that contains both group & response columns\n",
    "        str_group: a string that specifies group name\n",
    "        str_resp: a string that specifies response name\n",
    "        '''\n",
    "        if df_scored is None:\n",
    "            print(\"Error: no scored file for decile_lift() !!!!\")   \n",
    "\n",
    "        else:\n",
    "            # group by decile\n",
    "            deciles = df_scored.groupby([self.str_group]).agg({self.str_resp: [np.size, np.mean]})\n",
    "            deciles.columns=deciles.columns.droplevel(level=0)\n",
    "\n",
    "            deciles = deciles.reset_index(drop=False)\n",
    "            deciles['random_select'] = df_scored[self.str_resp].mean()\n",
    "\n",
    "            deciles.rename(columns = {'size':'cust_cnt','mean':'response_rate'}, inplace=True)\n",
    "            deciles['lift'] = deciles['response_rate'] / deciles['random_select']\n",
    "\n",
    "\n",
    "            # deciles['rand']=df_scored[self.str_resp].mean()\n",
    "            # deciles['lift']=deciles['mean']/df_scored[self.str_resp].mean()\n",
    "            # deciles['group_num']=np.arange(1,11,1)\n",
    "\n",
    "            deciles_record = deciles.reset_index(drop=True)\n",
    "\n",
    "            deciles_record['cnt_name'] =str('decile_cnt_')+ deciles_record.group.astype(str)\n",
    "            deciles_record['rr_name'] =str('decile_rr_')+ deciles_record.group.astype(str)\n",
    "            deciles_record['lift_name']=str('decile_lift_')+ deciles_record.group.astype(str)\n",
    "\n",
    "            deciles_cnt= pd.DataFrame(deciles_record['cust_cnt'].values,index=deciles_record.cnt_name).T\n",
    "            deciles_cnt_new = deciles_cnt.reset_index(drop=True)\n",
    "\n",
    "            deciles_rr= pd.DataFrame(deciles_record['response_rate'].values,index=deciles_record.rr_name).T\n",
    "            deciles_rr_new = deciles_rr.reset_index(drop=True)\n",
    "\n",
    "            deciles_lift= pd.DataFrame(deciles_record['lift'].values,index=deciles_record.lift_name).T\n",
    "            deciles_lift_new = deciles_lift.reset_index(drop=True)\n",
    "            deciles_score = pd.concat([deciles_cnt_new,deciles_rr_new,deciles_lift_new], axis=1)\n",
    "\n",
    "        return deciles_score, deciles\n",
    "    \n",
    "    \n",
    "    def maximum_ks(self, df_scored):\n",
    "        # Revised by Shawn on 20 Jun 2017\n",
    "        \"\"\"\n",
    "            df_in: a dataframe that contains both group & response columns\n",
    "            str_score: a string that specifies score name\n",
    "            str_resp: a string that specifies response name\n",
    "        \"\"\"\n",
    "        if df_scored is None:\n",
    "            print(\"Error: no scored file for for maximum_ks() !!!!\")\n",
    "        else:\n",
    "            # Max KS\n",
    "            max_ks_sort=df_scored.sort_values([self.str_score],ascending=False)\n",
    "            max_ks_sort['response']=df_scored[self.str_resp]\n",
    "            max_ks_sort.index=range(1,len(max_ks_sort)+1)\n",
    "            max_ks_sort['cum_good']=max_ks_sort.response.cumsum()\n",
    "            max_ks_sort['cum_bad']=max_ks_sort.index - max_ks_sort.cum_good\n",
    "            max_ks_sort['cum_good_rate'] = max_ks_sort.cum_good / max_ks_sort.response.sum()\n",
    "            max_ks_sort['cum_bad_rate']= max_ks_sort.cum_bad / (max_ks_sort.response.size-max_ks_sort.response.sum())\n",
    "            max_ks_sort['cum_rand_rate']= max_ks_sort.index / max_ks_sort.response.size\n",
    "            max_ks_sort['ks'] = max_ks_sort.cum_good_rate - max_ks_sort.cum_bad_rate\n",
    "\n",
    "            max_ks_score = max_ks_sort[(max_ks_sort.ks==max_ks_sort.ks.max())]\n",
    "            max_ks_score = max_ks_score[['cum_good_rate','cum_rand_rate','ks']]\n",
    "            max_ks_score.rename(columns={'cum_rand_rate':'max_ks_pop','ks':'max_ks'}, inplace=True)\n",
    "            max_ks_score = max_ks_score.reset_index(drop=True)\n",
    "\n",
    "        return max_ks_score, max_ks_sort\n",
    "    \n",
    "    def c_stat(self, df_scored):\n",
    "        # Revised by Shawn on 20 Jun 2017\n",
    "        \"\"\"\n",
    "            df_in: a dataframe that contains both group & response columns\n",
    "            str_score: a string that specifies score name\n",
    "            str_resp: a string that specifies response name\n",
    "        \"\"\"\n",
    "        if df_scored is None:\n",
    "            print(\"Error: no scored file for c_stat() !!!!\")\n",
    "        else:\n",
    "            # C-stat / concordant %\n",
    "            c_stat_sort=df_scored.sort_values([self.str_score],ascending=True)\n",
    "            c_stat_sort['response']=df_scored[self.str_resp]\n",
    "            c_stat_sort=c_stat_sort.reset_index(drop=True)\n",
    "            c_stat_sort['rp']=c_stat_sort.index\n",
    "            num_resp=c_stat_sort.response.sum()\n",
    "            rp_resp_sum=sum(c_stat_sort.response*c_stat_sort.rp)\n",
    "            row_count=c_stat_sort.response.count()\n",
    "            c_stat=(rp_resp_sum-0.5*num_resp*(num_resp-1))/(num_resp*(row_count-num_resp))\n",
    "            c_stat_score=pd.DataFrame([c_stat],columns=['c_stat'])\n",
    "\n",
    "        return c_stat_score\n",
    "    \n",
    "    def rank_decile(self, df_scored):\n",
    "        # to evenly rank scored base into decile\n",
    "        if df_scored is None:\n",
    "            print(\"Error: no scored file for c_stat() !!!!\")\n",
    "        else:\n",
    "            df_ranked = pd.DataFrame(pd.qcut(df_scored[self.str_score], 10, labels=False))\n",
    "            df_ranked.rename(columns = {self.str_score : self.str_group}, inplace=True)\n",
    "            df_ranked[self.str_group] = 10 - df_ranked[self.str_group]\n",
    "            df_ranked_scored = pd.concat([df_scored, df_ranked], axis=1)\n",
    "\n",
    "        return df_ranked_scored\n",
    "    \n",
    "    def get_result(self, df_scored, int_iter_cnt):\n",
    "        lifts, lift_chart = self.decile_lift(df_scored)\n",
    "        maxks, lorz_curve = self.maximum_ks(df_scored)\n",
    "        cstat= self.c_stat(df_scored)\n",
    "\n",
    "        param=pd.concat([pd.DataFrame([int_iter_cnt],columns=['model_cnt']),\n",
    "                         pd.DataFrame([self.n_estimators],columns=['n_estimators']),\n",
    "                         pd.DataFrame([self.learning_rate],columns=['learning_rate']),\n",
    "                         pd.DataFrame([self.min_samples_split],columns=['min_samples_split']),\n",
    "                         pd.DataFrame([self.min_samples_leaf],columns=['min_samples_leaf']),\n",
    "                         pd.DataFrame([self.max_depth],columns=['max_depth']),\n",
    "                         pd.DataFrame([self.max_features],columns=['max_features']),\n",
    "                         pd.DataFrame([self.subsample],columns=['subsample']),\n",
    "                         pd.DataFrame([self.random_state],columns=['random_state']),\n",
    "                         pd.DataFrame([self.criterion],columns=['criterion'])\n",
    "                        ], axis=1)\n",
    "\n",
    "        model_kpi=pd.concat([pd.DataFrame([int_iter_cnt],columns=['model_cnt']), cstat, maxks, lifts], axis=1)\n",
    "\n",
    "        return param, model_kpi\n",
    "    \n",
    "    # Define plot\n",
    "    def lift_chart(self, df_deciles):\n",
    "        grp = df_deciles[self.fmt_group]\n",
    "        drr = df_deciles[self.fmt_resp_rate]\n",
    "        rrr = df_deciles[self.fmt_rand_rate]\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        line1,=ax.plot(grp,drr,marker='o',color='blue', lw=1.5)\n",
    "        line2,=ax.plot(grp,rrr,ls='dashed',color='gray',lw=1.5)\n",
    "\n",
    "        xtext = ax.set_xlabel('Deciles')\n",
    "        ytext = ax.set_ylabel('% Resp')\n",
    "\n",
    "        ax.set_xlim(0.5,10.5)\n",
    "        ax.set_xticks(range(1,11,1))\n",
    "\n",
    "        ax.set_ylim(0, max(drr)*(1.1))\n",
    "        ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda t1, _: '{:.0%}'.format(t1)))\n",
    "\n",
    "        txt1=str(\"Decile 1 R.R.: \" + '{:.1%}'.format(drr.loc[0]) + \"; Lift: \" + '{:3.2}'.format(drr.loc[0]/rrr.loc[0]))\n",
    "        txt2=str(\"Decile 2 R.R.: \" + '{:.1%}'.format(drr.loc[1]) + \"; Lift: \" + '{:3.2}'.format(drr.loc[1]/rrr.loc[1]))\n",
    "        txt3=str(\"Decile 3 R.R.: \" + '{:.1%}'.format(drr.loc[2]) + \"; Lift: \" + '{:3.2}'.format(drr.loc[2]/rrr.loc[2]))\n",
    "\n",
    "        plt.text(grp[1]-0.7, drr.loc[0]*0.99, txt1, ha='left', rotation=0, wrap=True)\n",
    "        plt.text(grp[2]-0.7, drr.loc[1]*0.99, txt2, ha='left', rotation=0, wrap=True)\n",
    "        plt.text(grp[3]-0.7, drr.loc[2]*0.99, txt3, ha='left', rotation=0, wrap=True)\n",
    "\n",
    "        plt.legend((line1, line2), ('Model', 'Random'), loc='upper right', bbox_to_anchor=[0.95,0.95], shadow=True)\n",
    "\n",
    "        plt.suptitle('Lift Chart', fontsize=14)\n",
    "        plt.show()\n",
    "\n",
    "        return\n",
    "    \n",
    "    def lorenz_curve(self, df_kstable, df_maxks):\n",
    "        lorenz=pd.DataFrame({'cum_good':df_kstable.cum_good_rate.values[list(range(1,len(df_kstable)+1,100))],\n",
    "                             'cum_rand':df_kstable.cum_rand_rate.values[list(range(1,len(df_kstable)+1,100))],\n",
    "                             'cum_bad':df_kstable.cum_bad_rate.values[list(range(1,len(df_kstable)+1,100))]})\n",
    "        t0 = lorenz.cum_rand.values\n",
    "        t1 = lorenz.cum_good.values\n",
    "        t2 = lorenz.cum_rand.values\n",
    "        t3 = lorenz.cum_bad.values\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        max_ks_val = df_maxks['max_ks'].values[0]\n",
    "        max_ks_pop = df_maxks['max_ks_pop'].values[0]\n",
    "        max_ks_cgr = df_maxks['cum_good_rate'].values[0]\n",
    "\n",
    "        line1,=ax.plot(t0,t1,ls='solid',color='blue', lw=1.5)\n",
    "        line2,=ax.plot(t0,t2,ls='dashed',color='green', lw=1.5)\n",
    "        line3,=ax.plot(np.array([max_ks_pop,max_ks_pop]),np.array([0,max_ks_cgr]),ls='dashdot',color='grey',lw=1.5)\n",
    "        line4,=ax.plot(np.array([0,max_ks_pop]),np.array([max_ks_cgr,max_ks_cgr]),ls='dashdot',color='grey',lw=1.5)\n",
    "        mark1,=ax.plot(max_ks_pop,max_ks_cgr,marker='>',markersize=10,color='blue')\n",
    "\n",
    "        txt=str(\"Max KS: \" + '{:.0%}'.format(max_ks_val) + \" at \" + '{:.0%}'.format(max_ks_pop) + \" of Population\")\n",
    "        plt.text(max_ks_pop + 0.03, max_ks_cgr - 0.01, txt, ha='left', rotation=0, wrap=True)\n",
    "\n",
    "        xtext = ax.set_xlabel('% Cumulative Population')\n",
    "        ytext = ax.set_ylabel('% Cumulative Good')\n",
    "\n",
    "        ax.set_xlim(0.,1.)\n",
    "        ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda t0, _: '{:.0%}'.format(t0)))\n",
    "\n",
    "        ax.set_ylim(0.,1.)\n",
    "        ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda t1, _: '{:.0%}'.format(t1)))\n",
    "\n",
    "        plt.legend((line1, line2), ('Model', 'Random'), loc='lower right', bbox_to_anchor=[0.95,0.1], shadow=True)\n",
    "\n",
    "        plt.suptitle('Lorenz Curve', fontsize=14)\n",
    "        plt.show()\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBM_Shawn():\n",
    "    def __init__(self,mode=None,df_train=None,df_valid=None,str_resp=None,str_id=None):\n",
    "        self.mode=mode\n",
    "        self.df_train=df_train\n",
    "        self.df_valid=df_valid\n",
    "        self.str_resp=str_resp ## response variable\n",
    "        self.str_id=str_id\n",
    "\n",
    "        self.train_base=self.df_train ## save the original training dataframe\n",
    "        self.param=pd.DataFrame() ## full set of parameters\n",
    "        self.model_kpi=pd.DataFrame()\n",
    "        self.importance=pd.DataFrame() ## full set of parameters\n",
    "        self.best_param=pd.DataFrame() ## best parameter\n",
    "        self.best_model_kpi=pd.DataFrame()\n",
    "        self.best_driver=pd.DataFrame()\n",
    "        self.best_model=None ## trained model with the best parameter\n",
    "\n",
    "        self.iter_cnt=1\n",
    "        \n",
    "        #to grid search all parameters and return the full set of parameters and KPIs\n",
    "        if self.mode is None or self.mode == 'superfast':\n",
    "            self.n_estimators= [70]\n",
    "            self.learning_rate= [0.1]\n",
    "            self.min_samples_split= [50,100]\n",
    "            self.min_samples_leaf= [25,50]\n",
    "            self.max_depth= [3,4,5,6]\n",
    "            self.max_features= ['sqrt']\n",
    "            self.subsample=[0.9]\n",
    "            self.random_state=[10]\n",
    "            self.criterion= ['friedman_mse'] # mae, mse\n",
    "        elif self.mode=='fast':\n",
    "            self.n_estimators= [70,80,90]\n",
    "            self.learning_rate= [0.1,0.2]\n",
    "            self.min_samples_split= [50,100,200]\n",
    "            self.min_samples_leaf= [25,50,100]\n",
    "            self.max_depth= [3,4,5,6]\n",
    "            self.max_features= ['sqrt']\n",
    "            self.subsample= [0.9]\n",
    "            self.random_state=[10]\n",
    "            self.criterion= ['friedman_mse'] # mae, mse\n",
    "        elif self.mode=='medium':\n",
    "            self.n_estimators= [80,90,100,120]\n",
    "            self.learning_rate= [0.1,0.2,0.3]\n",
    "            self.min_samples_split = [0.001,0.003,0.005,0.01]\n",
    "            self.min_samples_leaf= [0.0005,0.0015,0.0025,0.005]\n",
    "            self.max_depth= [4,5,6,7,8]\n",
    "            self.max_features= ['sqrt']\n",
    "            self.subsample= [0.9]\n",
    "            self.random_state= [8051]\n",
    "            self.criterion= ['friedman_mse'] # mae, mse\n",
    "        elif self.mode=='slow':\n",
    "            self.n_estimators= [50,60,70,80,90,100]\n",
    "            self.learning_rate= [0.1,0.2,0.3,0.4,0.5]\n",
    "            self.min_samples_split = [50,100,200,500,1000]\n",
    "            self.min_samples_leaf= [25,50,100,250,500]\n",
    "            self.max_depth= [3,4,5,6,7,8,9,10]\n",
    "            self.max_features= ['sqrt']\n",
    "            self.subsample= [0.8,0.9]\n",
    "            self.random_state= [10]\n",
    "            self.criterion= ['friedman_mse'] # mae, mse\n",
    "        elif self.mode=='superslow':\n",
    "            self.n_estimators= [50,60,70,80,90,100]\n",
    "            self.learning_rate= [0.0001,0.001,0.01,0.1,0.2,0.3,0.4,0.5]\n",
    "            self.min_samples_split = [50,100,200,500,1000]\n",
    "            self.min_samples_leaf= [25,50,100,250,500]\n",
    "            self.max_depth= [3,4,5,6,7,8,9,10]\n",
    "            self.max_features= ['sqrt']\n",
    "            self.subsample= [0.7,0.8,0.9]\n",
    "            self.random_state= [10]\n",
    "            self.criterion= ['friedman_mse'] # mae, mse\n",
    "        elif self.mode=='customized':\n",
    "            self.n_estimators= [100]\n",
    "            self.learning_rate= [0.1]\n",
    "            self.min_samples_split = [50]\n",
    "            self.min_samples_leaf= [100]\n",
    "            self.max_depth= [8]\n",
    "            self.max_features= ['sqrt']\n",
    "            self.subsample= [0.9]\n",
    "            self.random_state= [10]\n",
    "            self.criterion= ['friedman_mse'] # mae, mse\n",
    "            \n",
    "        self.tot_iter = len(self.n_estimators)*len(self.learning_rate)*len(self.min_samples_split)*len(self.min_samples_leaf)*len(self.max_depth)*len(self.subsample)\n",
    "        \n",
    "        if self.df_train is None:\n",
    "            print(\"Training sample is missing !\")\n",
    "\n",
    "        if self.df_valid is None:\n",
    "            print(\"Validation sample is missing !\")\n",
    "\n",
    "        if self.str_resp is None:\n",
    "            print(\"Response variable is not specified !\")\n",
    "            \n",
    "    def _training(self):\n",
    "        ## data preparation\n",
    "        # training sample\n",
    "\n",
    "        y_train=self.df_train[self.str_resp].values\n",
    "        x_train=self.df_train.drop([self.str_resp,self.str_id], axis=1).values\n",
    "\n",
    "        # validation sample\n",
    "        y_valid=self.df_valid[self.str_resp].values\n",
    "        x_valid=self.df_valid.drop([self.str_resp,self.str_id], axis=1).values\n",
    "\n",
    "\n",
    "        # parameter tunning in Gradient Boosting\n",
    "        for i in self.n_estimators:\n",
    "            for j in self.learning_rate:\n",
    "                for k in self.min_samples_split:\n",
    "                    for l in self.min_samples_leaf:\n",
    "                        for m in self.max_depth:\n",
    "                            for n in self.max_features:\n",
    "                                for o in self.subsample:\n",
    "                                    for p in self.random_state:\n",
    "                                        for r in self.criterion:\n",
    "                                            # model training\n",
    "                                            clf = GradientBoostingLearner_Shawn(n_estimators= i,\n",
    "                                                                                learning_rate= j,\n",
    "                                                                                min_samples_split = k,\n",
    "                                                                                min_samples_leaf= l,\n",
    "                                                                                max_depth= m,\n",
    "                                                                                max_features= n,\n",
    "                                                                                subsample= o,\n",
    "                                                                                random_state= p,\n",
    "                                                                                criterion= r,\n",
    "                                                                                str_resp= self.str_resp\n",
    "                                                                                ).fit(x_train, y_train)\n",
    "                                            # Display progress\n",
    "                                            if divmod(self.iter_cnt,10)[1]==0:\n",
    "                                                print('Iteration: ' + str(self.iter_cnt) + ' out of ' + str(self.tot_iter))\n",
    "                                            # Validation sample\n",
    "                                            # to enahnce - \n",
    "                                                # 1) standardize ranking; \n",
    "                                                # 2) merge by cust_id (needed?)\n",
    "                                                # 3) to save train KPIs\n",
    "                                            p_valid_scored = pd.DataFrame(clf.predict_proba(x_valid))\n",
    "                                            p_valid_scored['response'] = self.df_valid[self.str_resp]\n",
    "                                            p_valid_scored = p_valid_scored.drop([0], axis=1)\n",
    "                                            p_valid_scored.rename(columns = {1:'score'}, inplace=True)\n",
    "                                            p_valid_ranked = clf.rank_decile(p_valid_scored)\n",
    "\n",
    "                                            # get parameters and KPIs\n",
    "                                            df_param, df_model_kpi = clf.get_result(p_valid_ranked, self.iter_cnt)\n",
    "\n",
    "                                            self.param=self.param.append(df_param)\n",
    "                                            self.model_kpi=self.model_kpi.append(df_model_kpi)\n",
    "\n",
    "                                            # get driver importance\n",
    "                                            df_imptc=pd.DataFrame(clf.feature_importances_,\n",
    "                                                                  index=self.df_train.drop([self.str_resp,self.str_id],axis=1).var().index)\n",
    "                                            df_imptc=df_imptc.T\n",
    "                                            df_imptc['model_cnt']=self.iter_cnt\n",
    "                                            self.importance=self.importance.append(df_imptc)\n",
    "\n",
    "                                            # ++self.iter_cnt\n",
    "                                            self.iter_cnt=self.iter_cnt+1\n",
    "\n",
    "\n",
    "        best_ref = self.model_kpi[(self.model_kpi['c_stat']==self.model_kpi['c_stat'].max())]\n",
    "        best_num = best_ref['model_cnt'].values[0]\n",
    "\n",
    "        print(\"Best Model Candidate : Model_cnt = \" + str(best_num))\n",
    "\n",
    "        self.best_param_t=pd.DataFrame(self.param[(self.param.model_cnt==best_num)])\n",
    "        self.best_param_t=self.best_param_t.reset_index(drop=True)\n",
    "\n",
    "        self.best_param=self.best_param_t.T\n",
    "        self.best_param.rename(columns={0:'Parameter Settings'}, inplace=True)\n",
    "        self.best_param=self.best_param.reset_index(drop=False)\n",
    "\n",
    "        self.best_model_kpi=pd.DataFrame(self.model_kpi[(self.model_kpi.model_cnt==best_num)]).T\n",
    "        self.best_model_kpi.rename(columns={0:'Model KPI'}, inplace=True)\n",
    "        self.best_model_kpi=self.best_model_kpi.reset_index(drop=False)\n",
    "\n",
    "        self.best_driver=pd.DataFrame(self.importance[(self.importance.model_cnt==best_num)]).T\n",
    "        self.best_driver.rename(columns={0:'Importance'}, inplace=True)\n",
    "        self.best_driver=self.best_driver.sort_values(['Importance'], ascending=False)\n",
    "        self.best_driver=self.best_driver.reset_index(drop=False)\n",
    "\n",
    "        # save the best model\n",
    "        self.best_model = GradientBoostingLearner_Shawn(n_estimators= self.best_param_t['n_estimators'].values[0],\n",
    "                                                        learning_rate= self.best_param_t['learning_rate'].values[0],\n",
    "                                                        min_samples_split = self.best_param_t['min_samples_split'].values[0],\n",
    "                                                        min_samples_leaf= self.best_param_t['min_samples_leaf'].values[0],\n",
    "                                                        max_depth= self.best_param_t['max_depth'].values[0],\n",
    "                                                        max_features= self.best_param_t['max_features'].values[0],\n",
    "                                                        subsample= self.best_param_t['subsample'].values[0],\n",
    "                                                        random_state= self.best_param_t['random_state'].values[0],\n",
    "                                                        criterion= self.best_param_t['criterion'].values[0],\n",
    "                                                        str_resp= self.str_resp).fit(x_train, y_train)\n",
    "        return\n",
    "    \n",
    "    def _validating(self, df_to_valid):\n",
    "        # validation sample\n",
    "        #y_valid=df_to_valid[self.str_resp].values\n",
    "        x_valid=df_to_valid.drop(self.str_resp, axis=1).values\n",
    "\n",
    "        p_predict=pd.DataFrame(self.best_model.predict_proba(x_valid))\n",
    "        p_actual=pd.DataFrame(df_to_valid[self.str_resp])\n",
    "        p_valid=pd.concat([p_predict, p_actual], axis=1)\n",
    "        p_valid.rename(columns = {0:'score_0',1:'score_1'}, inplace=True)\n",
    "        p_rank=pd.DataFrame(pd.qcut(p_valid['score_1'], 10, labels=False))\n",
    "        p_rank.rename(columns = {'score_1':'group'}, inplace=True)\n",
    "        p_valid2=pd.concat([p_valid, p_rank], axis=1)\n",
    "\n",
    "        # get parameters and KPIs\n",
    "        df_param=self.best_model.get_result(p_valid2)\n",
    "\n",
    "        return df_param\n",
    "\n",
    "    def _modeltest(self, df_to_test):\n",
    "        if df_to_test is None:\n",
    "            print(\"No scoring file is specified !!!\")\n",
    "            return\n",
    "        elif len(df_to_test.index)==0:\n",
    "            print(\"No records found from scoring file !!!\")\n",
    "            return\n",
    "        else:\n",
    "            df_id= pd.DataFrame(df_to_test[self.str_id])\n",
    "            df_resp = pd.DataFrame(df_to_test[self.str_resp])\n",
    "            # to_score = df_to_score.drop([self.str_id], axis=1)\n",
    "            scored_test = pd.DataFrame(self.best_model.predict_proba(df_to_test.drop([self.str_resp,self.str_id], axis=1).values))\n",
    "            scored_test['response'] = df_to_test[self.str_resp]\n",
    "            scored_test = scored_test.drop([0], axis=1)\n",
    "            scored_test.rename(columns = {1:'score'}, inplace=True)\n",
    "\n",
    "            ranked_test = self.best_model.rank_decile(scored_test)\n",
    "\n",
    "            # print(ranked_test)\n",
    "\n",
    "            test_lifts, test_lift_chart = self.best_model.decile_lift(ranked_test)\n",
    "            test_maxks, test_lorz_curve = self.best_model.maximum_ks(ranked_test)\n",
    "            test_cstat= self.best_model.c_stat(ranked_test)\n",
    "\n",
    "            print(test_lift_chart)\n",
    "\n",
    "            self.best_model.lift_chart(test_lift_chart)\n",
    "            self.best_model.lorenz_curve(test_lorz_curve, test_maxks)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
